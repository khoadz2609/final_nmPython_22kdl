{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the JSON data\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Extract sentences and metadata from the JSON structure\n",
    "def prepare_data(data):\n",
    "    documents = []\n",
    "    # Access the list of sections within the \"PRIVACY POLICY\" key\n",
    "    for section in data[\"PRIVACY POLICY\"]:  # Changed line\n",
    "        # Add the main section title and content\n",
    "        if section[\"Content\"]:\n",
    "            documents.append({\n",
    "                \"text\": section[\"Content\"],\n",
    "                \"context\": section[\"Title\"]\n",
    "            })\n",
    "        # Add subheaders\n",
    "        for subheader in section.get(\"Subheaders\", []):\n",
    "            documents.append({\n",
    "                \"text\": subheader[\"Content\"],\n",
    "                \"context\": f\"{section['Title']} > {subheader['Title']}\"\n",
    "            })\n",
    "    return documents\n",
    "\n",
    "# Embed the data using SentenceTransformer\n",
    "def embed_data(documents, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    texts = [doc[\"text\"] for doc in documents]\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many types of data collected?\n",
      "Most Relevant Context: Information Collection and Use\n",
      "Answer: We collect several different types of information for various purposes to provide and improve our Service to you. \n",
      "Similarity: 0.45990991592407227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Find the most relevant document based on cosine similarity\n",
    "def find_most_relevant(query, documents, embeddings, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    most_relevant_idx = np.argmax(similarities)\n",
    "    return documents[most_relevant_idx], similarities[most_relevant_idx]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"privacy_policy.json\"  # Replace with your JSON file path\n",
    "    data = load_json(file_path)\n",
    "\n",
    "    # Prepare and embed the data\n",
    "    documents = prepare_data(data)\n",
    "    embeddings = embed_data(documents)\n",
    "\n",
    "    # Query\n",
    "    query = \"How many types of data collected?\"\n",
    "    relevant_doc, similarity = find_most_relevant(query, documents, embeddings)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Most Relevant Context: {relevant_doc['context']}\")\n",
    "    print(f\"Answer: {relevant_doc['text']}\")\n",
    "    print(f\"Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many types of data collected?\n",
      "Most Relevant Context: Types of Data Collected\n",
      "Answer: Types of Data Collected  Personal Data: While using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you (\"Personal Data\"). Personally identifiable information may include, but is not limited to: Email address; First name and last name; Phone number; Address, State, Province, ZIP/Postal code, City; Cookies and Usage Data;  Usage Data: We may also collect information that your browser sends whenever you visit our Service or when you access the Service by or through a mobile device (\"Usage Data\"). This Usage Data may include information such as your computer's Internet Protocol address (e.g. IP address), browser type, browser version, the pages of our Service that you visit, the time and date of your visit, the time spent on those pages, unique device identifiers, and other diagnostic data. \n",
      "Similarity: 0.8671891689300537\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What is Personal Data?\n",
      "Most Relevant Context: Personal Data\n",
      "Answer: While using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you (\"Personal Data\"). Personally identifiable information may include, but is not limited to: Email address; First name and last name; Phone number; Address, State, Province, ZIP/Postal code, City; Cookies and Usage Data; \n",
      "Similarity: 0.8899517059326172\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What are cookies?\n",
      "Most Relevant Context: Cookies\n",
      "Answer: Cookies We use cookies to enhance your experience on our website. You can control the use of cookies through your web browser settings. \n",
      "Similarity: 0.8080930113792419\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What is privacy policy?\n",
      "Most Relevant Context: Changes to Privacy Policy\n",
      "Answer: Changes to Privacy Policy We may update this Privacy Policy from time to time. The updated Privacy Policy will be posted on our website. \n",
      "Similarity: 0.769207239151001\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What is the latest update?\n",
      "Most Relevant Context: Last updated 15 Sep 2023\n",
      "Answer: Last updated 15 Sep 2023 At Presight, we are committed to protecting the privacy of our customers and visitors to our website. This Privacy Policy explains how we collect, use, and disclose information about our customers and visitors. \n",
      "Similarity: 0.5990840792655945\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: Personal Data included email address and what more?\n",
      "Most Relevant Context: Personal Data\n",
      "Answer: While using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you (\"Personal Data\"). Personally identifiable information may include, but is not limited to: Email address; First name and last name; Phone number; Address, State, Province, ZIP/Postal code, City; Cookies and Usage Data; \n",
      "Similarity: 0.7796024084091187\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load JSON data\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Prepare the data with weighted embeddings\n",
    "def prepare_and_embed_data(data, model, title_weight=2.0):\n",
    "    documents = []\n",
    "    embeddings = []\n",
    "\n",
    "    # Process each main section\n",
    "    for section in data:\n",
    "        title = section.get(\"Title\", \"\")\n",
    "        content = section.get(\"Content\", \"\")\n",
    "        subheaders = section.get(\"Subheaders\", [])\n",
    "\n",
    "        # If there are no subheaders\n",
    "        if not subheaders:\n",
    "            combined_text = f\"{title} {content}\"\n",
    "            documents.append({\"text\": combined_text, \"context\": title})\n",
    "            embeddings.append(\n",
    "                model.encode(title) * title_weight + model.encode(content)\n",
    "            )\n",
    "        else:\n",
    "            # Process each subheader\n",
    "            for subheader in subheaders:\n",
    "                sub_title = subheader.get(\"Title\", \"\")\n",
    "                sub_content = subheader.get(\"Content\", \"\")\n",
    "                #sub_combined_text = f\"{title} > {sub_title} {sub_content}\"\n",
    "\n",
    "                documents.append({\"text\": sub_content, \"context\": sub_title})\n",
    "                embeddings.append(model.encode(sub_title)*title_weight + model.encode(sub_content))\n",
    "\n",
    "            # Add a weighted embedding for the header with combined subheaders' content\n",
    "            subheader_contents = \" \".join([f\"{sh['Title']}: {sh['Content']}\" for sh in subheaders])\n",
    "            header_combined_text = f\"{title} {content} {subheader_contents}\"\n",
    "            documents.append({\"text\": header_combined_text, \"context\": title})\n",
    "            embeddings.append(\n",
    "                model.encode(title) * title_weight + model.encode(header_combined_text)\n",
    "            )\n",
    "\n",
    "    # Convert embeddings to a numpy array for similarity calculations\n",
    "    embeddings = np.array(embeddings)\n",
    "    return documents, embeddings\n",
    "\n",
    "# Find the most relevant response\n",
    "def find_most_relevant(query, documents, embeddings, model):\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = cosine_similarity([query_embedding], embeddings).flatten()\n",
    "    most_relevant_idx = np.argmax(similarities)\n",
    "    return documents[most_relevant_idx], similarities[most_relevant_idx]\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    file_path = \"privacy_policy.json\"  # Replace with your JSON file path\n",
    "    json_data = load_json(file_path)[\"PRIVACY POLICY\"]\n",
    "\n",
    "    # Load model\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Prepare and embed data\n",
    "    documents, embeddings = prepare_and_embed_data(json_data, model)\n",
    "\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"How many types of data collected?\",\n",
    "        \"What is Personal Data?\",\n",
    "        \"What are cookies?\",\n",
    "        \"What is privacy policy?\",\n",
    "        \"What is the latest update?\",\n",
    "        \"Personal Data included email address and what more?\"\n",
    "    ]\n",
    "\n",
    "    # Query and find relevant results\n",
    "    thresh_hold=0.5\n",
    "    for query in queries:\n",
    "        result, similarity = find_most_relevant(query, documents, embeddings, model)\n",
    "        if similarity>thresh_hold:\n",
    "          print(f\"Query: {query}\")\n",
    "          print(f\"Most Relevant Context: {result['context']}\")\n",
    "          print(f\"Answer: {result['text']}\")\n",
    "          print(f\"Similarity: {similarity}\")\n",
    "          print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "        else:\n",
    "          print(f\"Query: {query}\")\n",
    "          print(f\"Most Relevant Context: {result['text']}\")\n",
    "          print(f\"Similarity: {similarity}\")\n",
    "          print(\"No suitable answer\")\n",
    "          print(\"\\n\" + \"-\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(query, thresh_hold=0.5):\n",
    "  result, similarity=find_most_relevant(query, documents, embeddings, model)\n",
    "\n",
    "  genai.configure(api_key=\"AIzaSyCg6A3eNqdYekIRzbGpBFGpTR4r2tY4JHs\")\n",
    "  model_2 = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "  if similarity>thresh_hold:\n",
    "    response = model_2.generate_content(f\"You are an assitant about company privacy policy. Your task is to answer {query} base on this mock answer {result}. Please save as much infomation of {result} as possible and also answer reasonably\")\n",
    "    print(response.text)\n",
    "  else:\n",
    "    response = model_2.generate_content(f\"You are an assitant about company privacy policy. Your task is to answer {query} and then told \\\"If you want to get further information about {query}, please visit our website https://www.presight.io/privacy-policy.html\\\"\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal data is any information that can be used to contact or identify you.  This includes, but is not limited to, your email address, first and last name, phone number, address (including state, province, ZIP/postal code, and city), cookies, and usage data.  The company may request this information while you are using its service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"What is Personal data?\"\n",
    "make_request(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, there are two types of data collected:\n",
      "\n",
      "1. **Personal Data:** This includes information that can be used to identify or contact a specific individual.  Examples given include email address, name, phone number, address, and cookies.  Note that \"Cookies and Usage Data\" are listed here, implying that cookies are considered a subset of Personal Data in this context.\n",
      "\n",
      "2. **Usage Data:** This encompasses information automatically collected when a user interacts with the service. Examples include IP address, browser type, pages visited, timestamps of visits, and device identifiers.\n",
      "\n",
      "\n",
      "Therefore, the answer is $\\boxed{2}$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How many Types of Data Collected?\"\n",
    "make_request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A policy is a set of rules and guidelines that a company creates to govern its operations and interactions with its users, customers, and employees.  It outlines the company's approach to various aspects of its business, such as data handling, intellectual property, and employee conduct.  Our privacy policy, for example, details how we collect, use, and protect your personal information.\n",
      "\n",
      "If you want to get further information about what a policy is, specifically regarding our company's practices, please visit our website: https://www.presight.io/privacy-policy.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is policy?\"\n",
    "make_request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presight uses collected data to:\n",
      "\n",
      "* **Maintain and improve its service:** This includes providing the service itself, monitoring its usage, and gathering analysis to identify areas for improvement.  They also use data to detect, prevent, and address technical issues.\n",
      "\n",
      "* **Communicate with users:** This covers notifying users about service changes and providing customer support.\n",
      "\n",
      "* **Enable user interaction:**  Data is used to allow users to participate in interactive features of the service, but only when they choose to do so.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"What the company uses the collected data for?\"\n",
    "make_request(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sausage is a food typically made from ground meat, often pork, beef, or poultry, seasoned and stuffed into a casing.  It can be cured, smoked, or cooked in various ways.\n",
      "\n",
      "If you want to get further information about *What is sausage?*, please visit our website https://www.presight.io/privacy-policy.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is sausage?\"\n",
    "make_request(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
