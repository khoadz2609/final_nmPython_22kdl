{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3ikSDjRmGqq"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "  <h2><b>Ho Chi Minh University of Science</b></h2>\n",
        "  <h3><b>Mathematics & Computer Science Faculty</b></h3>\n",
        "  <img src='https://th.bing.com/th/id/R.7298e6a7f00d000e22456c9977085835?rik=DqP9BjBZsGKPxw&pid=ImgRaw&r=0' width=\"250px\">\n",
        "  <h1><b>COURSE PROJECT: PYTHON FOR DATA SCIENCE</b></h1>\n",
        "  <ul style=\"list-style-type: none; padding: 0;\">\n",
        "    <li>\n",
        "      <table style=\"margin: 0 auto; border-collapse: collapse; width: 50%;\">\n",
        "        <thead>\n",
        "          <tr>\n",
        "            <th style=\"border: 1px solid black; padding: 8px;\">Full Name</th>\n",
        "            <th style=\"border: 1px solid black; padding: 8px;\">Student ID</th>\n",
        "          </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "          <tr>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">Nguyễn Lê Lâm Phúc</td>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">22280066</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">Mạc Minh Phúc</td>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">22280065</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">Trần Đại Lộc</td>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">22280053</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">Nguyễn Lê Đăng Khoa</td>\n",
        "            <td style=\"border: 1px solid black; padding: 8px;\">22280047</td>\n",
        "          </tr>\n",
        "        </tbody>\n",
        "      </table>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Question 1:** LLM Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from typing import Union, List\n",
        "import dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load API key from environment variables\n",
        "dotenv.load_dotenv()\n",
        "api_key = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"API key not found. Please set the 'GOOGLE_API_KEY' environment variable.\")\n",
        "\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Text translation and language detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PromptTemplates:\n",
        "    \"\"\"\n",
        "    A utility class for generating prompts for language detection and translation.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_language_detection_prompt(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Generates a prompt to detect the language of the given text.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text for language detection.\n",
        "\n",
        "        Returns:\n",
        "            str: A prompt instructing the model to detect the language.\n",
        "        \"\"\"\n",
        "        examples = \"\"\"\n",
        "        Example inputs and outputs:\n",
        "        Text: \"Hello world\" -> en\n",
        "        Text: \"Bonjour le monde\" -> fr\n",
        "        Text: \"Xin chào thế giới\" -> vi\n",
        "        Text: \"こんにちは世界\" -> ja\n",
        "\n",
        "        Now detect the language for this text and respond only with the ISO 639-1 code:\n",
        "        \"\"\"\n",
        "        return f\"{examples} {text}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_translation_prompt(text: str, target_lang: str) -> str:\n",
        "        \"\"\"\n",
        "        Generates a prompt to translate the given text into a target language.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text to be translated.\n",
        "            target_lang (str): The ISO 639-1 code of the target language.\n",
        "\n",
        "        Returns:\n",
        "            str: A prompt instructing the model to translate the text.\n",
        "        \"\"\"\n",
        "        examples = f\"\"\"\n",
        "        Example translations:\n",
        "        Input: \"Hello\", Target: es -> \"Hola\"\n",
        "        Input: \"Good morning\", Target: fr -> \"Bonjour\"\n",
        "        Input: \"Thank you\", Target: vi -> \"Cảm ơn\"\n",
        "\n",
        "        Translate this text into {target_lang} only responding with the translated text:\n",
        "        \"\"\"\n",
        "        return f\"{examples} {text}\"\n",
        "\n",
        "class TranslationService:\n",
        "    \"\"\"\n",
        "    A service class for detecting language and translating text using a generative AI model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initializes the TranslationService class, setting up configurations for the generative AI model\n",
        "        and preparing it for language detection and translation tasks.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): The API key required to authenticate and access the generative AI service.\n",
        "        \"\"\"\n",
        "\n",
        "        # Configure the genai library with the provided API key.\n",
        "        # This step authenticates the client with the generative AI service and enables secure access.\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # Initialize a generative AI model with the specified name and configuration parameters.\n",
        "        # This instance will be used to generate responses for language detection and translation.\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name=\"gemini-1.5-flash\",  # Specifies the version of the AI model to use.\n",
        "            generation_config={\n",
        "                \"temperature\": 1,  # Controls randomness in responses. A higher value increases diversity.\n",
        "                \"top_p\": 0.95,  # Implements nucleus sampling. Tokens are chosen from the top 95% cumulative probability.\n",
        "                \"top_k\": 40,  # Limits token selection to the top 40 most probable tokens for added coherence.\n",
        "                \"max_output_tokens\": 2048,  # Sets the maximum length for generated responses, preventing excessively long outputs.\n",
        "                \"response_mime_type\": \"text/plain\",  # Specifies the output format as plain text.\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Instantiate the PromptTemplates class, which provides predefined prompts for the generative model.\n",
        "        # These templates ensure consistent and effective communication with the model for tasks like\n",
        "        # detecting the language of input text and translating text into a target language.\n",
        "        self.prompt_templates = PromptTemplates()\n",
        "\n",
        "\n",
        "    def detect_language(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Detects the language of the given text.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text for language detection.\n",
        "\n",
        "        Returns:\n",
        "            str: The ISO 639-1 code of the detected language.\n",
        "        \"\"\"\n",
        "        prompt = self.prompt_templates.get_language_detection_prompt(text)\n",
        "        response = self.model.generate_content(prompt)\n",
        "        return response.text.strip().lower()\n",
        "\n",
        "    def translate(self, text: str, target_lang: str) -> str:\n",
        "        \"\"\"\n",
        "        Translates the given text into the target language.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text to be translated.\n",
        "            target_lang (str): The ISO 639-1 code of the target language.\n",
        "\n",
        "        Returns:\n",
        "            str: The translated text. If the source and target languages are the same, returns the input text.\n",
        "        \"\"\"\n",
        "        # Detect the source language\n",
        "        source_lang = self.detect_language(text)\n",
        "\n",
        "        # If source and target languages match, return the original text\n",
        "        if source_lang == target_lang:\n",
        "            return text\n",
        "\n",
        "        # Generate a translation prompt and get the translated content\n",
        "        prompt = self.prompt_templates.get_translation_prompt(text, target_lang)\n",
        "        response = self.model.generate_content(prompt)\n",
        "        return response.text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle text translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_single_text(input_json: dict) -> str:\n",
        "    \"\"\"\n",
        "    Translates a single text string from the input JSON to the specified destination language.\n",
        "\n",
        "    Args:\n",
        "        input_json (dict): A dictionary containing:\n",
        "            - 'text' (str): The text to be translated.\n",
        "            - 'dest_language' (str): The target language code for translation.\n",
        "\n",
        "    Returns:\n",
        "        str: The translated text.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the 'text' field is not a string.\n",
        "    \"\"\"\n",
        "    # Extract the 'text' field from the input JSON, defaulting to an empty string if missing.\n",
        "    text = input_json.get('text', '')\n",
        "\n",
        "    # Ensure the 'text' field is a string; raise an error if not.\n",
        "    if not isinstance(text, str):\n",
        "        raise ValueError(\"Text must be a string\")\n",
        "\n",
        "    # Extract the destination language code from the input JSON, defaulting to an empty string if missing.\n",
        "    language = input_json.get('dest_language', '')\n",
        "\n",
        "    # Create an instance of the translation service using a provided API key.\n",
        "    translator = TranslationService(api_key)\n",
        "\n",
        "    # Translate the text to the specified destination language and return the result.\n",
        "    return translator.translate(text, language)\n",
        "\n",
        "def translate_multiple_texts(input_json: dict) -> List[str]:\n",
        "    \"\"\"\n",
        "    Translates multiple text strings from the input JSON to the specified destination language.\n",
        "\n",
        "    Args:\n",
        "        input_json (dict): A dictionary containing:\n",
        "            - 'text' (List[str]): A list of text strings to be translated.\n",
        "            - 'dest_language' (str): The target language code for translation.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of translated text strings.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the 'text' field is not a list of strings.\n",
        "    \"\"\"\n",
        "    # Extract the 'text' field from the input JSON, defaulting to an empty list if missing.\n",
        "    texts = input_json.get('text', [])\n",
        "\n",
        "    # Ensure the 'text' field is a list of strings; raise an error if not.\n",
        "    if not isinstance(texts, list) or not all(isinstance(t, str) for t in texts):\n",
        "        raise ValueError(\"Text must be a list of strings\")\n",
        "\n",
        "    # Extract the destination language code from the input JSON, defaulting to an empty string if missing.\n",
        "    language = input_json.get('dest_language', '')\n",
        "\n",
        "    # Create an instance of the translation service using a provided API key.\n",
        "    translator = TranslationService(api_key)\n",
        "\n",
        "    # Translate each text string in the list to the specified destination language.\n",
        "    return [translator.translate(text, language) for text in texts]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hola'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ví dụ 1: Dịch một văn bản đơn lẻ\n",
        "json_1 = {\n",
        "    'text': 'Hello',\n",
        "    'dest_language': 'es'\n",
        "}\n",
        "\n",
        "\n",
        "translate_single_text(json_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question 1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Xin chào', 'Tôi là Peter', 'Bạn khỏe không?']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ví dụ 2: Dịch nhiều văn bản\n",
        "json_2 = {\n",
        "    'text': ['Hello', 'I am Peter',' How are you?'],\n",
        "    'dest_language': 'vi'\n",
        "}\n",
        "translate_multiple_texts(json_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I love you']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_3 = {\n",
        "    'text':['私はあなたを愛しています'],\n",
        "    'dest_language':'en'\n",
        "}\n",
        "translate_multiple_texts(json_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqUMh_9OsdOX"
      },
      "source": [
        "##**Question 2:** Chatbot Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-avjhyQtqMa"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrqnqpJSCp7K",
        "outputId": "eb4f1aba-631e-475d-8307-87a1af157fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in c:\\users\\khoanguyen\\miniconda3\\lib\\site-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejrjM42l0Co8",
        "outputId": "69b76c79-3092-4a27-f402-c050293e19bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in c:\\users\\khoanguyen\\miniconda3\\lib\\site-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\khoanguyen\\miniconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\khoanguyen\\miniconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZPbkXMww3ILE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Y4zPbrt1Ue"
      },
      "source": [
        "### Crawling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1tu7Y2z00Fbj"
      },
      "outputs": [],
      "source": [
        "# Get the website URL\n",
        "url='https://www.presight.io/privacy-policy.html'\n",
        "result= requests.get(url)\n",
        "soup=BeautifulSoup(result.text,'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fdAi4HV12-8P"
      },
      "outputs": [],
      "source": [
        "def parse_elements(elements):\n",
        "    \"\"\"\n",
        "    Parse elements from HTML and structure them into a JSON format.\n",
        "\n",
        "    Args:\n",
        "        elements (list): List of HTML elements to parse.\n",
        "\n",
        "    Returns:\n",
        "        dict: Parsed data structured as a JSON.\n",
        "    \"\"\"\n",
        "    data = {\"PRIVACY POLICY\": []}\n",
        "    prev_element = None\n",
        "    current_header = None\n",
        "\n",
        "    # Skip unnecessary part, find and crawl only relevant data\n",
        "    for element in elements[3:]:\n",
        "        if element.name == 'i':\n",
        "            handle_italic_element(element, current_header, prev_element)\n",
        "        elif element.name == 'h2':\n",
        "            current_header = handle_header_element(element, prev_element, current_header, data)\n",
        "        elif element.name in ['p', 'li']:\n",
        "            handle_content_element(element, current_header)\n",
        "\n",
        "        prev_element = element\n",
        "\n",
        "    if current_header:\n",
        "        data[\"PRIVACY POLICY\"].append(current_header)\n",
        "\n",
        "    return data\n",
        "\n",
        "def handle_italic_element(element, current_header, prev_element):\n",
        "    \"\"\"\n",
        "    Handle italic elements (<i> tags) and add them as subheaders to construct a more reasonable JSON file.\n",
        "\n",
        "    Args:\n",
        "        element (bs4.element.Tag): The <i> element to process.\n",
        "        current_header (dict): The current header being processed.\n",
        "        prev_element (bs4.element.Tag): The previous element.\n",
        "    \"\"\"\n",
        "    if current_header:\n",
        "        current_header[\"Subheaders\"].append({\n",
        "            \"Title\": element.text.strip(),\n",
        "            \"Content\": \"\"\n",
        "        })\n",
        "    else:\n",
        "        current_header = {\n",
        "            \"Title\": prev_element.text.strip(),\n",
        "            \"Subheaders\": [\n",
        "                {\"Title\": element.text.strip(), \"Content\": \"\"}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "def handle_header_element(element, prev_element, current_header, data):\n",
        "    \"\"\"\n",
        "    Handle header elements (<h2> tags) and structure them accordingly.\n",
        "\n",
        "    Args:\n",
        "        element (bs4.element.Tag): The <h2> element to process.\n",
        "        prev_element (bs4.element.Tag): The previous element.\n",
        "        current_header (dict): The current header being processed.\n",
        "        data (dict): The main data dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: Updated current header.\n",
        "    \"\"\"\n",
        "    if element.text == \"Automated Edit Checks\":\n",
        "        if current_header:\n",
        "            current_header[\"Subheaders\"].append({\n",
        "                \"Title\": element.text.strip(),\n",
        "                \"Content\": \"\"\n",
        "            })\n",
        "    elif prev_element and prev_element.name == 'h2':\n",
        "        if current_header:\n",
        "            current_header[\"Subheaders\"].append({\n",
        "                \"Title\": element.text.strip(),\n",
        "                \"Content\": \"\"\n",
        "            })\n",
        "        else:\n",
        "            current_header = {\n",
        "                \"Title\": prev_element.text.strip(),\n",
        "                \"Subheaders\": [\n",
        "                    {\"Title\": element.text.strip(), \"Content\": \"\"}\n",
        "                ]\n",
        "            }\n",
        "    else:\n",
        "        if current_header:\n",
        "            data[\"PRIVACY POLICY\"].append(current_header)\n",
        "        current_header = {\"Title\": element.text.strip(), \"Content\": \"\", \"Subheaders\": []}\n",
        "\n",
        "    return current_header\n",
        "\n",
        "def handle_content_element(element, current_header):\n",
        "    \"\"\"\n",
        "    Handle content elements (<p> and <li> tags) and add content to the appropriate section.\n",
        "\n",
        "    Args:\n",
        "        element (bs4.element.Tag): The content element to process.\n",
        "        current_header (dict): The current header being processed.\n",
        "    \"\"\"\n",
        "    if current_header:\n",
        "        if current_header[\"Subheaders\"]:\n",
        "            current_header[\"Subheaders\"][-1][\"Content\"] += element.text.strip() + (\"; \" if element.name == 'li' else \" \")\n",
        "        else:\n",
        "            current_header[\"Content\"] += element.text.strip() + (\"; \" if element.name == 'li' else \" \")\n",
        "\n",
        "def split_first_element(data):\n",
        "    \"\"\"\n",
        "    Splits the first element in the PRIVACY POLICY into two distinct elements.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The original JSON data.\n",
        "\n",
        "    Returns:\n",
        "        dict: Updated JSON data with the first element split.\n",
        "    \"\"\"\n",
        "    result = {\"PRIVACY POLICY\": []}\n",
        "    for entry in data[\"PRIVACY POLICY\"]:\n",
        "        if entry[\"Title\"].startswith(\"Last updated\"):\n",
        "            result[\"PRIVACY POLICY\"].append({\n",
        "                \"Title\": \"Update date\",\n",
        "                \"Content\": entry[\"Title\"],\n",
        "                \"Subheaders\": []\n",
        "            })\n",
        "            result[\"PRIVACY POLICY\"].append({\n",
        "                \"Title\": \"Commitment\",\n",
        "                \"Content\": entry[\"Content\"],\n",
        "                \"Subheaders\": entry[\"Subheaders\"]\n",
        "            })\n",
        "        else:\n",
        "            result[\"PRIVACY POLICY\"].append(entry)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90wx51WUCbZy",
        "outputId": "e4ff67c6-9394-4acb-adf6-21b96ebb2199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"Title\": \"Update date\",\n",
            "        \"Content\": \"Last updated 15 Sep 2023\",\n",
            "        \"Subheaders\": []\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Commitment\",\n",
            "        \"Content\": \"At Presight, we are committed to protecting the privacy of our customers and visitors to our website. This Privacy Policy explains how we collect, use, and disclose information about our customers and visitors. \",\n",
            "        \"Subheaders\": []\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Information Collection and Use\",\n",
            "        \"Content\": \"We collect several different types of information for various purposes to provide and improve our Service to you. \",\n",
            "        \"Subheaders\": []\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "elements = soup.find_all(['p', 'h2', 'li', 'i'])\n",
        "parsed_data = parse_elements(elements)\n",
        "result = split_first_element(parsed_data)\n",
        "#Print first 3 elements in the JSON file\n",
        "print(json.dumps(result[\"PRIVACY POLICY\"][:3], indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFuA2rOuv3I4",
        "outputId": "82bbf46a-ac0b-41aa-f5eb-6c83c01e6476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been written to privacy_policy.json\n"
          ]
        }
      ],
      "source": [
        "# Write the JSON data to a file\n",
        "output_file = \"privacy_policy.json\"\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(result, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"Data has been written to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3baEoVvwD2U"
      },
      "source": [
        "### Embedding data and developing chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjHuugJyzBeb"
      },
      "source": [
        "#### Load API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KMP5U52OzQjN"
      },
      "outputs": [],
      "source": [
        "# Load API key from environment variables\n",
        "dotenv.load_dotenv()\n",
        "api_key_2 = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if not api_key_2:\n",
        "    raise ValueError(\"API key not found. Please set the 'GOOGLE_API_KEY' environment variable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLYCLnWdzUFL"
      },
      "source": [
        "#### Develop chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bu5Jy_WK3GUm"
      },
      "outputs": [],
      "source": [
        "class PrivacyPolicyAssistant:\n",
        "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", title_weight=2, thresh_hold=0.5, genai_api_key=\"\", file_path=\"privacy_policy.json\", max_file_size=1048576):\n",
        "        \"\"\"\n",
        "        Initializes the PrivacyPolicyAssistant.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the transformer model for embeddings.\n",
        "            title_weight (float): Weight for title embeddings in relevance calculations.\n",
        "            thresh_hold (float): Similarity threshold for relevance.\n",
        "            genai_api_key (str): API key for the generative AI model.\n",
        "            file_path (str): Path to the privacy policy JSON file.\n",
        "            max_file_size (int): Maximum size for saved history files (in bytes).\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.title_weight = title_weight\n",
        "        self.thresh_hold = thresh_hold\n",
        "        self.documents = []\n",
        "        self.embeddings = None\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        genai.configure(api_key=genai_api_key)\n",
        "        self.generative_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        self.file_path = file_path\n",
        "        self.max_file_size = max_file_size\n",
        "        self._prepare_and_embed_data()\n",
        "\n",
        "    def _load_json(self):\n",
        "        \"\"\"\n",
        "        Loads the privacy policy JSON data from the specified file.\n",
        "        \"\"\"\n",
        "        with open(self.file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            return json.load(file)\n",
        "\n",
        "    def _prepare_and_embed_data(self):\n",
        "        \"\"\"\n",
        "        Processes the privacy policy sections into documents and computes their embeddings.\n",
        "        Combines titles, contents, and subheaders to generate meaningful embeddings\n",
        "        for similarity-based querying.\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "        embeddings = []\n",
        "        data = self._load_json()[\"PRIVACY POLICY\"]\n",
        "\n",
        "        for section in data:\n",
        "            title = section.get(\"Title\", \"\")\n",
        "            content = section.get(\"Content\", \"\")\n",
        "            subheaders = section.get(\"Subheaders\", [])\n",
        "            if not subheaders:\n",
        "              # Handles sections without subheaders\n",
        "                combined_text = f\"{title} {content}\"\n",
        "                documents.append({\"text\": combined_text, \"context\": title})\n",
        "                # Adding weight to title to meet users' basic needs for concepts and definitions, avoiding information noise\n",
        "                embeddings.append(self.model.encode(title) * self.title_weight + self.model.encode(content))\n",
        "            else:\n",
        "              # Handles sections with subheaders\n",
        "                for subheader in subheaders:\n",
        "                    sub_title = subheader.get(\"Title\", \"\")\n",
        "                    sub_content = subheader.get(\"Content\", \"\")\n",
        "                    documents.append({\"text\": sub_content, \"context\": sub_title})\n",
        "                    embeddings.append(self.model.encode(sub_title) * self.title_weight + self.model.encode(sub_content))\n",
        "\n",
        "                subheader_contents = \" \".join([f\"{sh['Title']}: {sh['Content']}\" for sh in subheaders])\n",
        "                header_combined_text = f\"{title} {content} {subheader_contents}\"\n",
        "                documents.append({\"text\": header_combined_text, \"context\": title})\n",
        "                embeddings.append(self.model.encode(title) * self.title_weight + self.model.encode(header_combined_text))\n",
        "\n",
        "        self.documents = documents\n",
        "        self.embeddings = np.array(embeddings)\n",
        "\n",
        "    def save_history(self, file_path, user_message, bot_response):\n",
        "      \"\"\"\n",
        "        Saves a user-bot conversation history into a JSON file.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the file where history will be saved.\n",
        "            user_message (str): User's query or message.\n",
        "            bot_response (str): Generated response to the user's query.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "      new_exchange = {\"user\": user_message, \"bot\": bot_response}\n",
        "      new_content = json.dumps(new_exchange, indent=4)\n",
        "\n",
        "      if os.path.exists(file_path):\n",
        "          current_size = os.path.getsize(file_path)\n",
        "          write_mode = \"a\"\n",
        "      else:\n",
        "          current_size = 0\n",
        "          write_mode = \"w\"\n",
        "\n",
        "      new_content_size = len(new_content.encode(\"utf-8\"))\n",
        "      if current_size + new_content_size > self.max_file_size:\n",
        "          print(f\"Alert: File size limit of {self.max_file_size} bytes exceeded. Save aborted.\")\n",
        "          return\n",
        "\n",
        "      else:\n",
        "            if write_mode == \"a\":\n",
        "                # If the file exists and is not empty, append new data to the existing JSON array\n",
        "              with open(file_path, \"r+\", encoding=\"utf-8\") as f:\n",
        "                  f.seek(0, os.SEEK_END)\n",
        "                  f.seek(f.tell() - 1, os.SEEK_SET) # Adjusts the file pointer to overwrite the closing bracket\n",
        "                  f.truncate()\n",
        "                  f.write(\",\\n\")\n",
        "                  f.write(new_content)\n",
        "                  f.write(\"\\n]\")\n",
        "            else:\n",
        "                with open(file_path, write_mode, encoding=\"utf-8\") as f:\n",
        "                    f.write(\"[\\n\")\n",
        "                    f.write(new_content)\n",
        "                    f.write(\"\\n]\")\n",
        "\n",
        "    def find_most_relevant(self, query):\n",
        "        \"\"\"\n",
        "        Finds the most relevant privacy policy section for the given query using cosine similarity.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's query for which relevance is evaluated.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A dictionary of the most relevant document and its similarity score.\n",
        "        \"\"\"\n",
        "        query_embedding = self.model.encode(query)\n",
        "        similarities = cosine_similarity([query_embedding], self.embeddings).flatten()\n",
        "        most_relevant_idx = np.argmax(similarities)\n",
        "        return self.documents[most_relevant_idx], similarities[most_relevant_idx]\n",
        "\n",
        "    def make_request(self, query):\n",
        "        \"\"\"\n",
        "        Generates a response to the user's query based on the most relevant privacy policy section or fallback logic.\n",
        "        Args:\n",
        "            query (str): The user's query for the assistant.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        result, similarity = self.find_most_relevant(query)\n",
        "        if similarity > self.thresh_hold:\n",
        "            prompt = (f\"You are an assistant about company privacy policy. Answer {query} based on this mock answer {result}.\")\n",
        "        else:\n",
        "          # Handle cases where questions contain context about the information above\n",
        "          if \"this\" in query or \"that\" in query or \"above\" in query:\n",
        "            history = json.load(open(\"conversation_history.json\",\"r\"))\n",
        "            if len(history) > 0:\n",
        "              current_ques=history[-1][\"user\"]\n",
        "              current_ans=history[-1][\"bot\"]\n",
        "              prompt = (f\"You are an assitant about company privacy policy. Your task is to answer {query} which is sequenced from {current_ques} and your current answer {current_ans}\")\n",
        "            else:\n",
        "              print(\"Please give me further information about your context!!!\")\n",
        "          else:\n",
        "            # Provides a generic response with a link for more information\n",
        "            prompt = (f\"You are an assitant about company privacy policy. Your task is to answer {query} and then told \\\"If you want to get further information about {query}, please visit our website https://www.presight.io/privacy-policy.html\\\"\")\n",
        "\n",
        "        try:\n",
        "            response = self.generative_model.generate_content(prompt)\n",
        "            print(response.text)\n",
        "            self.save_history(\"conversation_history.json\",query,response.text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQARcYEg0sQI"
      },
      "source": [
        "#### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9r-Sf4Pn4Y4b",
        "outputId": "3cc80a11-cf67-4d83-b48e-0bda2f01e948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Personal Data is information that can be used to contact or identify you.  This may include, but is not limited to, your email address, first and last name, phone number, address (including state, province, ZIP/Postal code, and city), and cookies and usage data.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usage example\n",
        "assistant = PrivacyPolicyAssistant(genai_api_key=api_key_2)\n",
        "query = \"What is Personal Data?\"\n",
        "assistant.make_request(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "Fdwpcw4LrfDF",
        "outputId": "3010d039-f218-455d-ad90-78a17e48359c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, let's expand on what constitutes \"Personal Data\" as defined in our privacy policy:\n",
            "\n",
            "**Expanding on \"Personal Data is information that can be used to contact or identify you.\"**\n",
            "\n",
            "This means any information that, either alone or when combined with other information we hold, could reasonably be used to identify, contact, or locate you.  It's broader than just your name and address.  We consider the following categories as examples of Personal Data:\n",
            "\n",
            "* **Direct Identifiers:** This includes information that explicitly identifies you, such as:\n",
            "    * **Full Name:** Your given name and surname.\n",
            "    * **Email Address:** Your unique email account.\n",
            "    * **Phone Number:** Your mobile or landline number.\n",
            "    * **Postal Address:** Your full mailing address (street address, city, state/province, postal code/ZIP code, country).\n",
            "    * **Online Identifiers:**  Your IP address, user IDs, account usernames, and other online identifiers.\n",
            "    * **Government-issued IDs:** Driver's license number, passport number, national identification number (only if collected).\n",
            "\n",
            "* **Indirect Identifiers:**  These are pieces of information that, while not directly identifying you on their own, can be combined with other data to identify you.  Examples include:\n",
            "\n",
            "    * **Location Data:**  Your GPS coordinates, IP address geolocation data (approximate location based on your IP address).\n",
            "    * **Cookies and Usage Data:**  These are small data files stored on your device when you visit our website. They track your browsing activity, including pages visited, time spent on pages, and links clicked. This information, when combined with other data, can help identify you.\n",
            "    * **Device Information:** Your device type, operating system, browser type, and other technical details.\n",
            "    * **Demographic Data:** Information like your age range, gender, and interests, if collected.  (Note:  We specify in our policy *if* and *how* we collect demographic data).\n",
            "    * **Payment Information:**  Credit card numbers, bank account details (if applicable and handled securely according to PCI DSS standards or equivalent).\n",
            "    * **Health Information:** Any information related to your physical or mental health (only if collected with your explicit consent and handled in compliance with relevant health data regulations).\n",
            "\n",
            "\n",
            "**What is *not* typically considered Personal Data (unless combined with other identifiers):**\n",
            "\n",
            "* **Aggregated Data:**  Data that has been combined from many individuals in such a way that no single person can be identified.\n",
            "* **Anonymized Data:** Data where all identifying information has been removed.\n",
            "\n",
            "\n",
            "**Important Note:** This is not an exhaustive list. The specific types of Personal Data we collect will be detailed more precisely in our full privacy policy.  Any new categories of Personal Data collected will be clearly stated and subject to your consent where required by law.  Our policy will also outline the purposes for which we collect your Personal Data and how we protect it.  You should always review the full privacy policy for the most up-to-date and complete information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Query with previous context\n",
        "query_2 = \"Explain further about this?\"\n",
        "assistant.make_request(query_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LXrGYX8lzaCf",
        "outputId": "5ed1a027-1f15-4955-b5e1-26e62841b1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A policy is a set of principles that guide decision-making and behavior within an organization.  In the context of a company's privacy policy, it's a document that outlines how the company collects, uses, shares, and protects the personal information of its users or customers.  It details individual rights regarding their data and the company's responsibilities in handling it.\n",
            "\n",
            "If you want to get further information about what our specific privacy policy entails, please visit our website: https://www.presight.io/privacy-policy.html\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Query about information not in the data\n",
        "query_3 = \"What is policy?\"\n",
        "assistant.make_request(query_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rT9Q9DaPl9Pu",
        "outputId": "833dbcda-0fd7-4b06-90c8-d13135a173ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided text, yes, you may need to provide your email address as part of your Personal Data when using the service.  The policy explicitly lists \"Email address\" as an example of personally identifiable information that may be requested.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Yes/ No question\n",
        "query_4 = \"Do I need to provide my Email Address in Personal Data?\"\n",
        "assistant.make_request(query_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCri7jPznW4",
        "outputId": "1ff46503-8226-4f14-fb93-facf52c14239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'user': 'What is Personal Data?',\n",
              "  'bot': 'Personal Data is information that can be used to contact or identify you.  This may include, but is not limited to, your email address, first and last name, phone number, address (including state, province, ZIP/Postal code, and city), and cookies and usage data.\\n'},\n",
              " {'user': 'Explain further about this?',\n",
              "  'bot': 'Okay, let\\'s expand on what constitutes \"Personal Data\" as defined in our privacy policy:\\n\\n**Expanding on \"Personal Data is information that can be used to contact or identify you.\"**\\n\\nThis means any information that, either alone or when combined with other information we hold, could reasonably be used to identify, contact, or locate you.  It\\'s broader than just your name and address.  We consider the following categories as examples of Personal Data:\\n\\n* **Direct Identifiers:** This includes information that explicitly identifies you, such as:\\n    * **Full Name:** Your given name and surname.\\n    * **Email Address:** Your unique email account.\\n    * **Phone Number:** Your mobile or landline number.\\n    * **Postal Address:** Your full mailing address (street address, city, state/province, postal code/ZIP code, country).\\n    * **Online Identifiers:**  Your IP address, user IDs, account usernames, and other online identifiers.\\n    * **Government-issued IDs:** Driver\\'s license number, passport number, national identification number (only if collected).\\n\\n* **Indirect Identifiers:**  These are pieces of information that, while not directly identifying you on their own, can be combined with other data to identify you.  Examples include:\\n\\n    * **Location Data:**  Your GPS coordinates, IP address geolocation data (approximate location based on your IP address).\\n    * **Cookies and Usage Data:**  These are small data files stored on your device when you visit our website. They track your browsing activity, including pages visited, time spent on pages, and links clicked. This information, when combined with other data, can help identify you.\\n    * **Device Information:** Your device type, operating system, browser type, and other technical details.\\n    * **Demographic Data:** Information like your age range, gender, and interests, if collected.  (Note:  We specify in our policy *if* and *how* we collect demographic data).\\n    * **Payment Information:**  Credit card numbers, bank account details (if applicable and handled securely according to PCI DSS standards or equivalent).\\n    * **Health Information:** Any information related to your physical or mental health (only if collected with your explicit consent and handled in compliance with relevant health data regulations).\\n\\n\\n**What is *not* typically considered Personal Data (unless combined with other identifiers):**\\n\\n* **Aggregated Data:**  Data that has been combined from many individuals in such a way that no single person can be identified.\\n* **Anonymized Data:** Data where all identifying information has been removed.\\n\\n\\n**Important Note:** This is not an exhaustive list. The specific types of Personal Data we collect will be detailed more precisely in our full privacy policy.  Any new categories of Personal Data collected will be clearly stated and subject to your consent where required by law.  Our policy will also outline the purposes for which we collect your Personal Data and how we protect it.  You should always review the full privacy policy for the most up-to-date and complete information.\\n'},\n",
              " {'user': 'What is policy?',\n",
              "  'bot': \"A policy is a set of principles that guide decision-making and behavior within an organization.  In the context of a company's privacy policy, it's a document that outlines how the company collects, uses, shares, and protects the personal information of its users or customers.  It details individual rights regarding their data and the company's responsibilities in handling it.\\n\\nIf you want to get further information about what our specific privacy policy entails, please visit our website: https://www.presight.io/privacy-policy.html\\n\"},\n",
              " {'user': 'Do I need to provide my Email Address in Personal Data?',\n",
              "  'bot': 'Based on the provided text, yes, you may need to provide your email address as part of your Personal Data when using the service.  The policy explicitly lists \"Email address\" as an example of personally identifiable information that may be requested.\\n'}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print out the history conversation\n",
        "json.load(open(\"conversation_history.json\",\"r\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
